{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LO-6EPRuqfSo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c16c848c-179c-4dc9-dfea-86410a83cd10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting facenet-pytorch\n",
            "  Downloading facenet_pytorch-2.6.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (1.26.4)\n",
            "Collecting Pillow<10.3.0,>=10.2.0 (from facenet-pytorch)\n",
            "  Downloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (2.32.3)\n",
            "Collecting torch<2.3.0,>=2.2.0 (from facenet-pytorch)\n",
            "  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting torchvision<0.18.0,>=0.17.0 (from facenet-pytorch)\n",
            "  Downloading torchvision-0.17.2-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (4.66.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.2.0 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3.0,>=2.2.0->facenet-pytorch) (12.6.77)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.3.0,>=2.2.0->facenet-pytorch) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.3.0,>=2.2.0->facenet-pytorch) (1.3.0)\n",
            "Downloading facenet_pytorch-2.6.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m982.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.17.2-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, Pillow, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, facenet-pytorch\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: pillow 11.0.0\n",
            "    Uninstalling pillow-11.0.0:\n",
            "      Successfully uninstalled pillow-11.0.0\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n",
            "    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu121\n",
            "    Uninstalling torchvision-0.20.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-10.2.0 facenet-pytorch-2.6.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 torch-2.2.2 torchvision-0.17.2 triton-2.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "5d7f82675464455d9149c8bf4be50f62"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install facenet-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCLX8Hswf79E"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q PyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvgNgC7C41bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7a1a423-fd32-42d8-8eaf-c8835758ecff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qdrant-client\n",
            "  Downloading qdrant_client-1.12.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (1.67.1)\n",
            "Collecting grpcio-tools>=1.41.0 (from qdrant-client)\n",
            "  Downloading grpcio_tools-1.68.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.27.2)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (1.26.4)\n",
            "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.10.8 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (2.9.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (2.2.3)\n",
            "Collecting protobuf<6.0dev,>=5.26.1 (from grpcio-tools>=1.41.0->qdrant-client)\n",
            "  Downloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting grpcio>=1.41.0 (from qdrant-client)\n",
            "  Downloading grpcio-1.68.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant-client) (75.1.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.6)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.14.0)\n",
            "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant-client)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant-client) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant-client) (4.12.2)\n",
            "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.2.2)\n",
            "Downloading qdrant_client-1.12.1-py3-none-any.whl (267 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.2/267.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio_tools-1.68.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.68.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: protobuf, portalocker, hyperframe, hpack, grpcio, h2, grpcio-tools, qdrant-client\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.67.1\n",
            "    Uninstalling grpcio-1.67.1:\n",
            "      Successfully uninstalled grpcio-1.67.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed grpcio-1.68.0 grpcio-tools-1.68.0 h2-4.1.0 hpack-4.0.0 hyperframe-6.0.1 portalocker-2.10.1 protobuf-5.28.3 qdrant-client-1.12.1\n"
          ]
        }
      ],
      "source": [
        "!pip install qdrant-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKib3n43qK6S"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from facenet_pytorch import InceptionResnetV1\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gt4UQMftgCBS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e65ae468-eb54-472a-ed16-fd0c86f8d545"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        }
      ],
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Step 1: Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLFktCRQV451",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6811697-bd65-4a40-ad52-3f11091aaf48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxMd0fZYtxsy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b0d9585-c32a-4389-f2e2-eddab7facb1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data has been extracted to /content/data/\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "# Define the path to the file in your Google Drive\n",
        "zip_file_path = '/content/drive/MyDrive/archive_1.zip'\n",
        "extract_to_path = '/content/data/'  # Local directory in Colab\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to_path)\n",
        "\n",
        "print(f\"Data has been extracted to {extract_to_path}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbouATHBqPxW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "42b4c7fd17f046c69df06a33e4fff3f5",
            "dd8c478a848a41e18bc83b8ad165bbb1",
            "737562e4ee094cf3986544d26efacaea",
            "d3319622703248cf9c07715cb9b8561c",
            "af1b466a25684d8c9b3e2484d7ae361b",
            "e8e652ccc2024767a86bc6c1a4d1615d",
            "cf8f8598226a46a3b950d1dbf36e1c1c",
            "93c9d23f22894053ae9df0d3951d2f59",
            "d5ed923630714b1f91afc787a1ce15d2",
            "c87a89178c4a4fdb9480f8da9ee4cd51",
            "3fe76fb5daa74f40801a90e6fbff15b5"
          ]
        },
        "outputId": "704ce882-e534-41fa-b115-1e5c39dab02b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/107M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42b4c7fd17f046c69df06a33e4fff3f5"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load pre-trained FaceNet model\n",
        "model = InceptionResnetV1(pretrained='vggface2').eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhfSS0K2qSU_"
      },
      "outputs": [],
      "source": [
        "# Define image preprocessing pipeline\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((160, 160)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbPfXOl2p848",
        "outputId": "4b01b42a-e0a3-441d-9844-097184bb9fb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved embeddings for pins_Cristiano Ronaldo\n",
            "Saved embeddings for pins_jeff bezos\n",
            "Saved embeddings for pins_Lionel Messi\n",
            "Saved embeddings for pins_Megan Fox\n",
            "Saved embeddings for pins_Dwayne Johnson\n",
            "Saved embeddings for pins_Josh Radnor\n",
            "Saved embeddings for pins_Penn Badgley\n",
            "Saved embeddings for pins_Sarah Wayne Callies\n",
            "Saved embeddings for pins_Ben Affleck\n",
            "Saved embeddings for pins_Katherine Langford\n",
            "Saved embeddings for pins_Mark Zuckerberg\n",
            "Saved embeddings for pins_Robert De Niro\n",
            "Saved embeddings for pins_Tom Hiddleston\n",
            "Saved embeddings for pins_Avril Lavigne\n",
            "Saved embeddings for pins_Bill Gates\n",
            "Saved embeddings for pins_Brian J. Smith\n",
            "Saved embeddings for pins_Hugh Jackman\n",
            "Saved embeddings for pins_Rami Malek\n",
            "Saved embeddings for pins_Jason Momoa\n",
            "Saved embeddings for pins_Henry Cavil\n",
            "Saved embeddings for pins_Miley Cyrus\n",
            "Saved embeddings for pins_Sophie Turner\n",
            "Saved embeddings for pins_Logan Lerman\n",
            "Saved embeddings for pins_elon musk\n",
            "Saved embeddings for pins_Maria Pedraza\n",
            "Saved embeddings for pins_Adriana Lima\n",
            "Saved embeddings for pins_Jeremy Renner\n",
            "Saved embeddings for pins_Brenton Thwaites\n",
            "Saved embeddings for pins_Andy Samberg\n",
            "Saved embeddings for pins_Emilia Clarke\n",
            "Saved embeddings for pins_melissa fumero\n",
            "Saved embeddings for pins_Inbar Lavi\n",
            "Saved embeddings for pins_Richard Harmon\n",
            "Saved embeddings for pins_Christian Bale\n",
            "Saved embeddings for pins_Tom Holland\n",
            "Saved embeddings for pins_Jennifer Lawrence\n",
            "Saved embeddings for pins_grant gustin\n",
            "Saved embeddings for pins_Dominic Purcell\n",
            "Saved embeddings for pins_elizabeth olsen\n",
            "Saved embeddings for pins_Natalie Portman\n",
            "Saved embeddings for pins_Emma Stone\n",
            "Saved embeddings for pins_Wentworth Miller\n",
            "Saved embeddings for pins_Tuppence Middleton\n",
            "Saved embeddings for pins_Selena Gomez\n",
            "Saved embeddings for pins_barbara palvin\n",
            "Saved embeddings for pins_Zac Efron\n",
            "Saved embeddings for pins_Pedro Alonso\n",
            "Saved embeddings for pins_Zendaya\n",
            "Saved embeddings for pins_Shakira Isabel Mebarak\n",
            "Saved embeddings for pins_Stephen Amell\n",
            "Saved embeddings for pins_Anne Hathaway\n",
            "Saved embeddings for pins_Morena Baccarin\n",
            "Saved embeddings for pins_Taylor Swift\n",
            "Saved embeddings for pins_Irina Shayk\n",
            "Saved embeddings for pins_kiernen shipka\n",
            "Saved embeddings for pins_Lindsey Morgan\n",
            "Saved embeddings for pins_Tom Cruise\n",
            "Saved embeddings for pins_alycia dabnem carey\n",
            "Saved embeddings for pins_Lili Reinhart\n",
            "Saved embeddings for pins_Anthony Mackie\n",
            "Saved embeddings for pins_Maisie Williams\n",
            "Saved embeddings for pins_Bobby Morley\n",
            "Saved embeddings for pins_Gwyneth Paltrow\n",
            "Saved embeddings for pins_Nadia Hilker\n",
            "Saved embeddings for pins_Katharine Mcphee\n",
            "Saved embeddings for pins_Jessica Barden\n",
            "Saved embeddings for pins_gal gadot\n",
            "Saved embeddings for pins_amber heard\n",
            "Saved embeddings for pins_Madelaine Petsch\n",
            "Saved embeddings for pins_Robert Downey Jr\n",
            "Saved embeddings for pins_Jake Mcdorman\n",
            "Saved embeddings for pins_Mark Ruffalo\n",
            "Saved embeddings for pins_Eliza Taylor\n",
            "Saved embeddings for pins_Neil Patrick Harris\n",
            "Saved embeddings for pins_Chris Hemsworth\n",
            "Saved embeddings for pins_Johnny Depp\n",
            "Saved embeddings for pins_Alex Lawther\n",
            "Saved embeddings for pins_Keanu Reeves\n",
            "Saved embeddings for pins_Chris Evans\n",
            "Saved embeddings for pins_camila mendes\n",
            "Saved embeddings for pins_Amanda Crew\n",
            "Saved embeddings for pins_Krysten Ritter\n",
            "Saved embeddings for pins_Chris Pratt\n",
            "Saved embeddings for pins_ellen page\n",
            "Saved embeddings for pins_Brie Larson\n",
            "Saved embeddings for pins_tom ellis\n",
            "Saved embeddings for pins_margot robbie\n",
            "Saved embeddings for pins_Marie Avgeropoulos\n",
            "Saved embeddings for pins_Leonardo DiCaprio\n",
            "Saved embeddings for pins_Rebecca Ferguson\n",
            "Saved embeddings for pins_Jimmy Fallon\n",
            "Saved embeddings for pins_Elizabeth Lail\n",
            "Saved embeddings for pins_Danielle Panabaker\n",
            "Saved embeddings for pins_Tom Hardy\n",
            "Saved embeddings for pins_Millie Bobby Brown\n",
            "Saved embeddings for pins_scarlett johansson\n",
            "Saved embeddings for pins_Alexandra Daddario\n",
            "Saved embeddings for pins_Ursula Corbero\n",
            "Saved embeddings for pins_Natalie Dormer\n",
            "Saved embeddings for pins_Emma Watson\n",
            "Saved embeddings for pins_Rihanna\n",
            "Saved embeddings for pins_barack obama\n",
            "Saved embeddings for pins_Morgan Freeman\n",
            "Saved embeddings for pins_Alvaro Morte\n",
            "Saved embeddings for pins_Zoe Saldana\n"
          ]
        }
      ],
      "source": [
        "def generate_embedding(image_path):\n",
        "    # Load and preprocess image\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    img_tensor = preprocess(img).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "    # Generate embedding\n",
        "    with torch.no_grad():\n",
        "        embedding = model(img_tensor)\n",
        "    return embedding.squeeze().numpy()  # Convert to numpy array\n",
        "\n",
        "def save_embeddings():\n",
        "    data_dir = 'data/celebrity_images'\n",
        "    embedding_dir = 'data/embeddings'\n",
        "    os.makedirs(embedding_dir, exist_ok=True)\n",
        "\n",
        "    # Process each celebrity folder\n",
        "    for celebrity_name in os.listdir(data_dir):\n",
        "        celebrity_folder = os.path.join(data_dir, celebrity_name)\n",
        "        embeddings = []\n",
        "\n",
        "        for img_name in os.listdir(celebrity_folder):\n",
        "            img_path = os.path.join(celebrity_folder, img_name)\n",
        "            embedding = generate_embedding(img_path)  # Pass img_path here\n",
        "            embeddings.append(embedding)\n",
        "\n",
        "        # Save embeddings as a .npy file\n",
        "        embeddings = np.stack(embeddings)\n",
        "        np.save(os.path.join(embedding_dir, f\"{celebrity_name}.npy\"), embeddings)\n",
        "        print(f\"Saved embeddings for {celebrity_name}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    save_embeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvzSF9aiqKgA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6dbad99-59c9-4f8a-ed3e-764758c57ef5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collection 'celebrity_embeddings_3' already exists.\n",
            "Uploaded 203 embeddings for pins_Anne Hathaway\n",
            "Uploaded 179 embeddings for pins_Hugh Jackman\n",
            "Uploaded 141 embeddings for pins_Dwayne Johnson\n",
            "Uploaded 166 embeddings for pins_Chris Evans\n",
            "Uploaded 181 embeddings for pins_Tom Hiddleston\n",
            "Uploaded 146 embeddings for pins_Dominic Purcell\n",
            "Uploaded 158 embeddings for pins_Elizabeth Lail\n",
            "Uploaded 117 embeddings for pins_Josh Radnor\n",
            "Uploaded 178 embeddings for pins_Rebecca Ferguson\n",
            "Uploaded 175 embeddings for pins_Morena Baccarin\n",
            "Uploaded 133 embeddings for pins_Nadia Hilker\n",
            "Uploaded 212 embeddings for pins_Logan Lerman\n",
            "Uploaded 98 embeddings for pins_Cristiano Ronaldo\n",
            "Uploaded 122 embeddings for pins_Maria Pedraza\n",
            "Uploaded 127 embeddings for pins_Inbar Lavi\n",
            "Uploaded 226 embeddings for pins_Katherine Langford\n",
            "Uploaded 196 embeddings for pins_Andy Samberg\n",
            "Uploaded 138 embeddings for pins_Zendaya\n",
            "Uploaded 201 embeddings for pins_scarlett johansson\n",
            "Uploaded 122 embeddings for pins_Bill Gates\n",
            "Uploaded 189 embeddings for pins_Tom Holland\n",
            "Uploaded 181 embeddings for pins_Danielle Panabaker\n",
            "Uploaded 106 embeddings for pins_jeff bezos\n",
            "Uploaded 95 embeddings for pins_Mark Zuckerberg\n",
            "Uploaded 167 embeddings for pins_Jeremy Renner\n",
            "Uploaded 183 embeddings for pins_grant gustin\n",
            "Uploaded 102 embeddings for pins_Brian J. Smith\n",
            "Uploaded 237 embeddings for pins_Leonardo DiCaprio\n",
            "Uploaded 154 embeddings for pins_melissa fumero\n",
            "Uploaded 171 embeddings for pins_Krysten Ritter\n",
            "Uploaded 191 embeddings for pins_Zac Efron\n",
            "Uploaded 160 embeddings for pins_Keanu Reeves\n",
            "Uploaded 187 embeddings for pins_Gwyneth Paltrow\n",
            "Uploaded 141 embeddings for pins_Jessica Barden\n",
            "Uploaded 221 embeddings for pins_margot robbie\n",
            "Uploaded 209 embeddings for pins_Brenton Thwaites\n",
            "Uploaded 193 embeddings for pins_Maisie Williams\n",
            "Uploaded 139 embeddings for pins_Alvaro Morte\n",
            "Uploaded 184 embeddings for pins_Jason Momoa\n",
            "Uploaded 160 embeddings for pins_Rami Malek\n",
            "Uploaded 210 embeddings for pins_Emilia Clarke\n",
            "Uploaded 176 embeddings for pins_Chris Pratt\n",
            "Uploaded 167 embeddings for pins_Ursula Corbero\n",
            "Uploaded 192 embeddings for pins_Madelaine Petsch\n",
            "Uploaded 197 embeddings for pins_barbara palvin\n",
            "Uploaded 198 embeddings for pins_Natalie Dormer\n",
            "Uploaded 204 embeddings for pins_Sophie Turner\n",
            "Uploaded 156 embeddings for pins_Irina Shayk\n",
            "Uploaded 138 embeddings for pins_Bobby Morley\n",
            "Uploaded 162 embeddings for pins_Eliza Taylor\n",
            "Uploaded 195 embeddings for pins_Henry Cavil\n",
            "Uploaded 135 embeddings for pins_elon musk\n",
            "Uploaded 178 embeddings for pins_Miley Cyrus\n",
            "Uploaded 186 embeddings for pins_Selena Gomez\n",
            "Uploaded 139 embeddings for pins_Emma Stone\n",
            "Uploaded 133 embeddings for pins_Tuppence Middleton\n",
            "Uploaded 225 embeddings for pins_Alexandra Daddario\n",
            "Uploaded 178 embeddings for pins_Mark Ruffalo\n",
            "Uploaded 161 embeddings for pins_Marie Avgeropoulos\n",
            "Uploaded 113 embeddings for pins_Jimmy Fallon\n",
            "Uploaded 218 embeddings for pins_amber heard\n",
            "Uploaded 211 embeddings for pins_Emma Watson\n",
            "Uploaded 119 embeddings for pins_barack obama\n",
            "Uploaded 159 embeddings for pins_Stephen Amell\n",
            "Uploaded 177 embeddings for pins_Katharine Mcphee\n",
            "Uploaded 209 embeddings for pins_Megan Fox\n",
            "Uploaded 159 embeddings for pins_Sarah Wayne Callies\n",
            "Uploaded 159 embeddings for pins_Chris Hemsworth\n",
            "Uploaded 171 embeddings for pins_Penn Badgley\n",
            "Uploaded 156 embeddings for pins_Robert De Niro\n",
            "Uploaded 126 embeddings for pins_Ben Affleck\n",
            "Uploaded 221 embeddings for pins_elizabeth olsen\n",
            "Uploaded 154 embeddings for pins_Shakira Isabel Mebarak\n",
            "Uploaded 116 embeddings for pins_Neil Patrick Harris\n",
            "Uploaded 180 embeddings for pins_tom ellis\n",
            "Uploaded 105 embeddings for pins_Morgan Freeman\n",
            "Uploaded 179 embeddings for pins_Wentworth Miller\n",
            "Uploaded 150 embeddings for pins_Lili Reinhart\n",
            "Uploaded 162 embeddings for pins_camila mendes\n",
            "Uploaded 148 embeddings for pins_Richard Harmon\n",
            "Uploaded 191 embeddings for pins_Millie Bobby Brown\n",
            "Uploaded 166 embeddings for pins_Natalie Portman\n",
            "Uploaded 199 embeddings for pins_gal gadot\n",
            "Uploaded 124 embeddings for pins_Anthony Mackie\n",
            "Uploaded 192 embeddings for pins_Tom Cruise\n",
            "Uploaded 162 embeddings for pins_Avril Lavigne\n",
            "Uploaded 203 embeddings for pins_kiernen shipka\n",
            "Uploaded 213 embeddings for pins_Adriana Lima\n",
            "Uploaded 182 embeddings for pins_Johnny Depp\n",
            "Uploaded 233 embeddings for pins_Robert Downey Jr\n",
            "Uploaded 188 embeddings for pins_ellen page\n",
            "Uploaded 180 embeddings for pins_Jennifer Lawrence\n",
            "Uploaded 169 embeddings for pins_Brie Larson\n",
            "Uploaded 133 embeddings for pins_Rihanna\n",
            "Uploaded 86 embeddings for pins_Lionel Messi\n",
            "Uploaded 117 embeddings for pins_Amanda Crew\n",
            "Uploaded 211 embeddings for pins_alycia dabnem carey\n",
            "Uploaded 154 embeddings for pins_Christian Bale\n",
            "Uploaded 131 embeddings for pins_Taylor Swift\n",
            "Uploaded 125 embeddings for pins_Pedro Alonso\n",
            "Uploaded 152 embeddings for pins_Alex Lawther\n",
            "Uploaded 186 embeddings for pins_Zoe Saldana\n",
            "Uploaded 198 embeddings for pins_Tom Hardy\n",
            "Uploaded 169 embeddings for pins_Lindsey Morgan\n",
            "Uploaded 159 embeddings for pins_Jake Mcdorman\n"
          ]
        }
      ],
      "source": [
        "from qdrant_client import QdrantClient\n",
        "import numpy as np\n",
        "import os\n",
        "from qdrant_client.models import Distance, VectorParams\n",
        "from qdrant_client.http.models import VectorParams\n",
        "# Replace with your Qdrant cloud URL or Docker container IP\n",
        "qdrant_url = \"\"\n",
        "api_key = \"\"\n",
        "\n",
        "# Initialize Qdrant client (use the URL for remote instances)\n",
        "client = QdrantClient(\n",
        "    url=qdrant_url,\n",
        "    api_key=api_key  # If using cloud, include API key for authentication\n",
        ")\n",
        "\n",
        "# Define the collection name and check if it exists\n",
        "collection_name = \"celebrity_embeddings_3\"\n",
        "if not client.collection_exists(collection_name):\n",
        "    client.create_collection(\n",
        "        collection_name=collection_name,\n",
        "        vectors_config={\n",
        "            \"default\": VectorParams(size=512, distance=Distance.COSINE)\n",
        "        }\n",
        "    )\n",
        "    print(f\"Created collection: {collection_name}\")\n",
        "else:\n",
        "    print(f\"Collection '{collection_name}' already exists.\")\n",
        "\n",
        "def load_embeddings_to_qdrant():\n",
        "    embedding_dir = 'data/embeddings'  # Directory with your .npy files\n",
        "    point_id = 0  # Initialize a unique integer ID for each embedding\n",
        "\n",
        "    for celebrity_file in os.listdir(embedding_dir):\n",
        "        celebrity_name = os.path.splitext(celebrity_file)[0]\n",
        "        embeddings = np.load(os.path.join(embedding_dir, celebrity_file))\n",
        "\n",
        "        points = [\n",
        "            {\n",
        "                \"id\": point_id + i,  # Use a unique integer ID\n",
        "                \"vector\": {\"default\": embedding.tolist()},  # Specify the vector name \"default\"\n",
        "                \"payload\": {\"celebrity\": celebrity_name}\n",
        "            }\n",
        "            for i, embedding in enumerate(embeddings)\n",
        "        ]\n",
        "\n",
        "        # Update point_id to continue incrementing across files\n",
        "        point_id += len(points)\n",
        "\n",
        "        client.upsert(\n",
        "            collection_name=collection_name,\n",
        "            points=points\n",
        "        )\n",
        "        print(f\"Uploaded {len(points)} embeddings for {celebrity_name}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    load_embeddings_to_qdrant()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# upload_embeddings.py\n",
        "from qdrant_client import QdrantClient\n",
        "import numpy as np\n",
        "import os\n",
        "from qdrant_client.models import Distance, VectorParams, PointStruct\n",
        "\n",
        "# Qdrant connection configuration\n",
        "qdrant_url = \"https://34ef3520-a13f-4224-a4c5-f12c09b9a937.us-east4-0.gcp.cloud.qdrant.io\"\n",
        "api_key = \"DuT8NuJMBhg18S7HE6GC2tNZ1TYt-cg5iiciJML808W9OGo2uqcF0g\"\n",
        "\n",
        "# Initialize Qdrant client\n",
        "client = QdrantClient(\n",
        "    url=qdrant_url,\n",
        "    api_key=api_key\n",
        ")\n",
        "\n",
        "# Collection configuration\n",
        "collection_name = \"celebrity_embeddings_3\"\n",
        "vector_size = 512\n",
        "\n",
        "def ensure_collection():\n",
        "    \"\"\"Create collection if it doesn't exist\"\"\"\n",
        "    if not client.collection_exists(collection_name):\n",
        "        client.create_collection(\n",
        "            collection_name=collection_name,\n",
        "            vectors_config=VectorParams(size=vector_size, distance=Distance.COSINE)\n",
        "        )\n",
        "        print(f\"Created collection: {collection_name}\")\n",
        "    else:\n",
        "        print(f\"Collection '{collection_name}' already exists.\")\n",
        "\n",
        "def load_embeddings_to_qdrant():\n",
        "    \"\"\"Load embeddings from .npy files and upload to Qdrant\"\"\"\n",
        "    embedding_dir = 'data/embeddings'\n",
        "    point_id = 0\n",
        "\n",
        "    for celebrity_file in os.listdir(embedding_dir):\n",
        "        celebrity_name = os.path.splitext(celebrity_file)[0]\n",
        "        embeddings = np.load(os.path.join(embedding_dir, celebrity_file))\n",
        "\n",
        "        # Convert embeddings to float32 and handle NaN values\n",
        "        embeddings = np.nan_to_num(embeddings.astype(np.float32))\n",
        "\n",
        "        points = [\n",
        "            PointStruct(\n",
        "                id=point_id + i,\n",
        "                vector=embedding.tolist(),  # Convert numpy array to list\n",
        "                payload={\"celebrity\": celebrity_name}\n",
        "            )\n",
        "            for i, embedding in enumerate(embeddings)\n",
        "        ]\n",
        "\n",
        "        # Update point_id for next batch\n",
        "        point_id += len(points)\n",
        "\n",
        "        # Upload points in batches\n",
        "        batch_size = 100\n",
        "        for i in range(0, len(points), batch_size):\n",
        "            batch = points[i:i + batch_size]\n",
        "            client.upsert(\n",
        "                collection_name=collection_name,\n",
        "                points=batch\n",
        "            )\n",
        "\n",
        "        print(f\"Uploaded {len(points)} embeddings for {celebrity_name}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    ensure_collection()\n",
        "    load_embeddings_to_qdrant()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UowZYGq0h5aX",
        "outputId": "8806cc22-4731-48f5-e833-c03a1156125e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created collection: celebrity_embeddings_3\n",
            "Uploaded 203 embeddings for pins_Anne Hathaway\n",
            "Uploaded 179 embeddings for pins_Hugh Jackman\n",
            "Uploaded 141 embeddings for pins_Dwayne Johnson\n",
            "Uploaded 166 embeddings for pins_Chris Evans\n",
            "Uploaded 181 embeddings for pins_Tom Hiddleston\n",
            "Uploaded 146 embeddings for pins_Dominic Purcell\n",
            "Uploaded 158 embeddings for pins_Elizabeth Lail\n",
            "Uploaded 117 embeddings for pins_Josh Radnor\n",
            "Uploaded 178 embeddings for pins_Rebecca Ferguson\n",
            "Uploaded 175 embeddings for pins_Morena Baccarin\n",
            "Uploaded 133 embeddings for pins_Nadia Hilker\n",
            "Uploaded 212 embeddings for pins_Logan Lerman\n",
            "Uploaded 98 embeddings for pins_Cristiano Ronaldo\n",
            "Uploaded 122 embeddings for pins_Maria Pedraza\n",
            "Uploaded 127 embeddings for pins_Inbar Lavi\n",
            "Uploaded 226 embeddings for pins_Katherine Langford\n",
            "Uploaded 196 embeddings for pins_Andy Samberg\n",
            "Uploaded 138 embeddings for pins_Zendaya\n",
            "Uploaded 201 embeddings for pins_scarlett johansson\n",
            "Uploaded 122 embeddings for pins_Bill Gates\n",
            "Uploaded 189 embeddings for pins_Tom Holland\n",
            "Uploaded 181 embeddings for pins_Danielle Panabaker\n",
            "Uploaded 106 embeddings for pins_jeff bezos\n",
            "Uploaded 95 embeddings for pins_Mark Zuckerberg\n",
            "Uploaded 167 embeddings for pins_Jeremy Renner\n",
            "Uploaded 183 embeddings for pins_grant gustin\n",
            "Uploaded 102 embeddings for pins_Brian J. Smith\n",
            "Uploaded 237 embeddings for pins_Leonardo DiCaprio\n",
            "Uploaded 154 embeddings for pins_melissa fumero\n",
            "Uploaded 171 embeddings for pins_Krysten Ritter\n",
            "Uploaded 191 embeddings for pins_Zac Efron\n",
            "Uploaded 160 embeddings for pins_Keanu Reeves\n",
            "Uploaded 187 embeddings for pins_Gwyneth Paltrow\n",
            "Uploaded 141 embeddings for pins_Jessica Barden\n",
            "Uploaded 221 embeddings for pins_margot robbie\n",
            "Uploaded 209 embeddings for pins_Brenton Thwaites\n",
            "Uploaded 193 embeddings for pins_Maisie Williams\n",
            "Uploaded 139 embeddings for pins_Alvaro Morte\n",
            "Uploaded 184 embeddings for pins_Jason Momoa\n",
            "Uploaded 160 embeddings for pins_Rami Malek\n",
            "Uploaded 210 embeddings for pins_Emilia Clarke\n",
            "Uploaded 176 embeddings for pins_Chris Pratt\n",
            "Uploaded 167 embeddings for pins_Ursula Corbero\n",
            "Uploaded 192 embeddings for pins_Madelaine Petsch\n",
            "Uploaded 197 embeddings for pins_barbara palvin\n",
            "Uploaded 198 embeddings for pins_Natalie Dormer\n",
            "Uploaded 204 embeddings for pins_Sophie Turner\n",
            "Uploaded 156 embeddings for pins_Irina Shayk\n",
            "Uploaded 138 embeddings for pins_Bobby Morley\n",
            "Uploaded 162 embeddings for pins_Eliza Taylor\n",
            "Uploaded 195 embeddings for pins_Henry Cavil\n",
            "Uploaded 135 embeddings for pins_elon musk\n",
            "Uploaded 178 embeddings for pins_Miley Cyrus\n",
            "Uploaded 186 embeddings for pins_Selena Gomez\n",
            "Uploaded 139 embeddings for pins_Emma Stone\n",
            "Uploaded 133 embeddings for pins_Tuppence Middleton\n",
            "Uploaded 225 embeddings for pins_Alexandra Daddario\n",
            "Uploaded 178 embeddings for pins_Mark Ruffalo\n",
            "Uploaded 161 embeddings for pins_Marie Avgeropoulos\n",
            "Uploaded 113 embeddings for pins_Jimmy Fallon\n",
            "Uploaded 218 embeddings for pins_amber heard\n",
            "Uploaded 211 embeddings for pins_Emma Watson\n",
            "Uploaded 119 embeddings for pins_barack obama\n",
            "Uploaded 159 embeddings for pins_Stephen Amell\n",
            "Uploaded 177 embeddings for pins_Katharine Mcphee\n",
            "Uploaded 209 embeddings for pins_Megan Fox\n",
            "Uploaded 159 embeddings for pins_Sarah Wayne Callies\n",
            "Uploaded 159 embeddings for pins_Chris Hemsworth\n",
            "Uploaded 171 embeddings for pins_Penn Badgley\n",
            "Uploaded 156 embeddings for pins_Robert De Niro\n",
            "Uploaded 126 embeddings for pins_Ben Affleck\n",
            "Uploaded 221 embeddings for pins_elizabeth olsen\n",
            "Uploaded 154 embeddings for pins_Shakira Isabel Mebarak\n",
            "Uploaded 116 embeddings for pins_Neil Patrick Harris\n",
            "Uploaded 180 embeddings for pins_tom ellis\n",
            "Uploaded 105 embeddings for pins_Morgan Freeman\n",
            "Uploaded 179 embeddings for pins_Wentworth Miller\n",
            "Uploaded 150 embeddings for pins_Lili Reinhart\n",
            "Uploaded 162 embeddings for pins_camila mendes\n",
            "Uploaded 148 embeddings for pins_Richard Harmon\n",
            "Uploaded 191 embeddings for pins_Millie Bobby Brown\n",
            "Uploaded 166 embeddings for pins_Natalie Portman\n",
            "Uploaded 199 embeddings for pins_gal gadot\n",
            "Uploaded 124 embeddings for pins_Anthony Mackie\n",
            "Uploaded 192 embeddings for pins_Tom Cruise\n",
            "Uploaded 162 embeddings for pins_Avril Lavigne\n",
            "Uploaded 203 embeddings for pins_kiernen shipka\n",
            "Uploaded 213 embeddings for pins_Adriana Lima\n",
            "Uploaded 182 embeddings for pins_Johnny Depp\n",
            "Uploaded 233 embeddings for pins_Robert Downey Jr\n",
            "Uploaded 188 embeddings for pins_ellen page\n",
            "Uploaded 180 embeddings for pins_Jennifer Lawrence\n",
            "Uploaded 169 embeddings for pins_Brie Larson\n",
            "Uploaded 133 embeddings for pins_Rihanna\n",
            "Uploaded 86 embeddings for pins_Lionel Messi\n",
            "Uploaded 117 embeddings for pins_Amanda Crew\n",
            "Uploaded 211 embeddings for pins_alycia dabnem carey\n",
            "Uploaded 154 embeddings for pins_Christian Bale\n",
            "Uploaded 131 embeddings for pins_Taylor Swift\n",
            "Uploaded 125 embeddings for pins_Pedro Alonso\n",
            "Uploaded 152 embeddings for pins_Alex Lawther\n",
            "Uploaded 186 embeddings for pins_Zoe Saldana\n",
            "Uploaded 198 embeddings for pins_Tom Hardy\n",
            "Uploaded 169 embeddings for pins_Lindsey Morgan\n",
            "Uploaded 159 embeddings for pins_Jake Mcdorman\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "42b4c7fd17f046c69df06a33e4fff3f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd8c478a848a41e18bc83b8ad165bbb1",
              "IPY_MODEL_737562e4ee094cf3986544d26efacaea",
              "IPY_MODEL_d3319622703248cf9c07715cb9b8561c"
            ],
            "layout": "IPY_MODEL_af1b466a25684d8c9b3e2484d7ae361b"
          }
        },
        "dd8c478a848a41e18bc83b8ad165bbb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8e652ccc2024767a86bc6c1a4d1615d",
            "placeholder": "​",
            "style": "IPY_MODEL_cf8f8598226a46a3b950d1dbf36e1c1c",
            "value": "100%"
          }
        },
        "737562e4ee094cf3986544d26efacaea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93c9d23f22894053ae9df0d3951d2f59",
            "max": 111898327,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5ed923630714b1f91afc787a1ce15d2",
            "value": 111898327
          }
        },
        "d3319622703248cf9c07715cb9b8561c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c87a89178c4a4fdb9480f8da9ee4cd51",
            "placeholder": "​",
            "style": "IPY_MODEL_3fe76fb5daa74f40801a90e6fbff15b5",
            "value": " 107M/107M [00:00&lt;00:00, 175MB/s]"
          }
        },
        "af1b466a25684d8c9b3e2484d7ae361b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8e652ccc2024767a86bc6c1a4d1615d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf8f8598226a46a3b950d1dbf36e1c1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93c9d23f22894053ae9df0d3951d2f59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5ed923630714b1f91afc787a1ce15d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c87a89178c4a4fdb9480f8da9ee4cd51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fe76fb5daa74f40801a90e6fbff15b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}